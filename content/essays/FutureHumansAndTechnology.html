---
title: "Future, Humans and Technology"
date: 2023-04-06T14:01:50+02:00
draft: false
filename: "FutureHumansAndTechnology.pdf"
summary: "Should we have an optimistic or pessimistic outlook towards the future? In this essay I argue that we need to find a middle ground and learn from both perspectives."
tags: ["ethics", "technology ethics"]
---

<p>This essay is on technology ethics, more specifically on the
    question, how we should deal with technological advances. It
    incorporates two very different views, on the one hand the view by Bill
    Joy, as presented in his essay “Why the Future Doesn’t Need Us” <span
    class="citation" data-cites="whythefuture">(Joy 2000)</span>, which I
    call the pessimistic view. On the other hand it looks at the view of
    John G. Messerly in his essay “I’m glad the future doesn’t need us: a
    critique of Joy’s pessimistic futurism” <span class="citation"
    data-cites="imglad">(Messerly 2003)</span> that I will call the
    optimistic view. It is my goal to show that neither view is entirely
    correct and that instead of going to extremes, we would do better to
    listen to both sides and find a middle ground that serves our interests
    best.</p>
    <p>I will begin with discussing both points of view. In his essay “Why
    the future doesn’t need us”, Bill Joy argues, that technological
    advances, if left unchecked, may come with “unintended consequences”. He
    bases his argument on a thought experiment, where “computer scientists
    succeed in developing intelligent machines that can do all things better
    than human beings can do them”. I will use the term “AI” (artificial
    intelligence) as substitute for “intelligent machines”. Given the
    thought experiment, Joy argues, that “the fate of the human race would
    be at the mercy of the machines”, because “the human race might easily
    permit itself to drift into a position of such dependence on the
    machines that it would have no practical choice but to accept all of the
    machines’ decisions”. We can see this phenomena play out in small scale
    with modern technology. With online shopping, we permitted ourselves to
    fall into a position of dependence, because it is more convenient to go
    online and order precisely what we want, instead of driving to a shop
    and trying to find what we are looking for. I think, that we can call
    this a “light dependence” on technology, because in the absence of that
    technology, our lives wouldn’t be in danger (at least for most of us).
    Stronger dependency on technology is found in computer technology as
    such. Imagine a scenario where, due to a solar flare, all electronics
    went offline for a couple of weeks. In this scenario more than just a
    little inconvenience is to be expected. Because much in our lives
    depends on computer technology, our lives would be (severely) impacted.
    We would still be able to survive, because we could revert to “the old
    ways”, but much of our daily comfort would be gone. But if, as Joy
    postulates, we fall into a dependence on AI, where AI plays a
    significant role in our lives and takes over many essential tasks, in
    our infrastructure etc., it becomes clear, that in case of a blackout
    our dependence on AI would result in catastrophic outcomes.</p>
    <p>Joy acknowledges that this is only one possible outcome. The other
    possibility is the dystopian view that, because “human work (…) will be
    superfluous”, the “masses” will be at the mercy of the “elite”, which,
    in the end, will engineer life in a way that it “will most certainly not
    be free”, instead human beings will be “reduced to the status of
    domestic animals”. In this, undebatably pessimistic, scenario, AI would
    not be in complete control, but will be a tool, used by the “elite”, to
    control the “masses” and thus limiting freedom excessively. I think,
    that this scenario, just like the one discussed above, is to be taken
    seriously. To dismiss the possibility of this happening would be
    reckless, because it would ignore the history of humanity, which seldom
    shows great respect of the ruling class towards the ruled masses. The
    bottom line, I think, is that a greater discussion is necessary to
    decide about the ownership of technology of as great a scope as AI. To
    envision a future that incorporates AI in a scope as predicted by Joy,
    would require us to not only develop the technological means, but the
    social ones too. While this is not the place to defend this theses, I
    think that the connection between technology and human beings is much
    closer than we think it is. It goes as far as seeing humans not as “homo
    sapiens”, but rather as “homo technologicus”, for a lack of a better
    term. If we take a look at the rapid changes in technology in the recent
    years and the accompanying changes in human behavior, we can view humans
    as beings that change themselves by changing their technology. Think
    about the way modern communication technology changed our lives and the
    ways we interact with each other, to a point, where, e.g. in modern
    dating, technology becomes the primary means of (initial) communication,
    instead of one-on-one talking. If that is the case, we can make it a
    point to think more careful about the technology we introduce in our
    lives and, furthermore, we can argue that, if we introduce a technology,
    we should think about the consequences it has (and could have) on us and
    ask the follow-up question, how we have to change, to make the
    technology best serve us, and therefore produce the best possible
    outcome for our new understanding of ourselves.</p>
    <p>Joy concludes his discussion by arguing that in his thought
    experiment all possibilities “are (…) either undesirable or unachievable
    or both”. Therefore, he proposes to “limit development of the
    technologies that are too dangerous, by limiting our pursuit of certain
    kinds of knowledge”. As already hinted by the discussion above, I don’t
    agree with his conclusion. While I agree that there are dangers on the
    road ahead, burying our heads in the sand won’t deflect them. First off,
    it seems impossible to me to completely stop either the development or
    the pursuit of knowledge of AI technology. While some people might
    adhere to this call, others, I will call them rogue scientists, will
    continue their studies. If those rogue scientists succeed in their
    undertaking, they will have all the knowledge, while the rest of the
    world will be oblivious to the workings of AI, and will thus depend on
    those rogue scientists. Therefore it would be better if the development
    and study were open to the public, because technology such as AI, which
    has a large impact on our lives, should not be developed and studied
    behind closed doors, but in the open, to allow for independent control,
    and understanding of the technology.</p>
    <p>We can summarize the pessimistic view on technology as the view, that
    technology can pose a significant threat to humanity and thus should be
    either strictly controlled in development, or banned completely.</p>
    <p>I will now turn to the opposite view. John G. Messerly, in direct
    response to Joy, in his essay “I’m glad the future doesn’t need us: a
    critique of Joy’s pessimistic futurism”, argues, that technology might
    improve our lives, maybe even in a dramatic way, and we should therefore
    not worry about unintended consequences. Same as Joy, Messerly’s core
    argument concerns the unintended consequences that might result from
    technology. He argues, that “it is hard to quibble about the existence
    of unintended consequences”, because if “the future is unknown, some
    consequences are unknown”. Because we cannot know about the unintended
    consequences of any technology, Messerly concludes, that Joy’s
    conclusion to “cease and desist in the research, development, and use of
    21st-century technologies” cannot be supported, because he cannot know,
    that these unintended consequences will occur. Instead, he counters that
    “it might well be that newer technologies will lead to a safer
    world”.</p>
    <p>In what follows, Messerly discusses all of Joy’s arguments and
    refutes them by implicitly relying on his base premise, that the future
    is unknown, therefore it is not sure what will happen. As technically
    true that premise is, as unsatisfying it appears to me. Yes, we don’t
    know, what will happen. Yes, “we may increase our survival chances by
    switching control to more failsafe robots designed and programmed by our
    minds”. Yes, sometimes we “<em>underestimate</em> our design abilities”.
    But all these arguments look at the issue from the completely opposite
    side. What is unsatisfying to me, is the ignorance on potential threats
    that might emerge. While I don’t fully agree with Joy on all his
    arguments, I also don’t think, that we should dismiss them too easily.
    After all, there is wisdom to be gained by picturing the worst case
    scenario, even if it never occurs. To assume that we don’t know,
    therefore we shouldn’t assume the worst, but instead assume that things
    will turn out okay, or even better, is the exact opposite of Joy’s
    argument. Instead Messerly could argue, that we don’t know, therefore we
    cannot know if the consequences will be good or bad. Only because we
    might have a more optimistic point of view, doesn’t mean, that
    pessimistic scenarios are to be dismissed. The only real conclusion that
    Messerly can draw from his base premise, that we cannot foresee the
    future and its consequences, is that we should withhold any opinion on
    the subject, because if we cannot meaningfully speak about pessimistic
    outcomes, we cannot meaningfully speak about optimistic ones.</p>
    <p>We can summarize the optimistic view on technology as the view that
    assumes that technology might pose a significant threat to humanity, but
    because we cannot know for sure, we might as well assume positive
    outcomes and therefore not limit the development and study of
    technology.</p>
    <p>As optimistic as Messerly is, and as easy as he dismisses Joy’s
    conclusion, that we should stop or limit the development and study of
    certain technologies, it seems to me as if Messerly doesn’t agree with
    himself. In his essay “How Computer Games Affect CS (and Other)
    Students’ School Performance” <span class="citation"
    data-cites="howcomputergames">(Messerly 2004)</span>, Messerly argues,
    that video games severely impact students’ lives due to their addictive
    nature. He argues, that gaming experience leads to the collapse of one’s
    social life, that gaming seldom offers positive lessons and that games
    don’t round out a contemporary computer science education <span
    class="citation" data-cites="howcomputergames">(Messerly 2004,
    31)</span>. He concludes his essay with the plea, that “we can only hope
    (that) gamers begin to recognize that the real world holds much more
    reward (…), promising more positive experience, knowledge, joy, and
    love” <span class="citation" data-cites="howcomputergames">(Messerly
    2004, 31)</span>. I think, that we can reconstruct Messerly’s argument
    to fit into the general discussion of this essay.</p>
    <p>Video games, I am sure you will agree, are technology. They require
    computer technology to work, because they are programs and assets that
    are only possible with computer technology. The intended consequences
    (i.e. goal) of video games is to entertain people. That some people
    develop addictive dependencies on video games, is (in most cases) not
    intended, therefore these addictions are unintended consequences.
    Therefore, Messerly argues, that it would be better, would students not
    play video games, because of their unintended consequence of addiction,
    and instead rely on other means, that is, the “real world”. This
    conclusion leads to me asking two questions: First, if video games
    showcase, that technology can have unintended, negative consequences,
    why should we look at technology in an all positive light? Second,
    considering the term “real world”, where does it begin and end? I will
    now try to give answers to that questions.</p>
    <p>The first question, if video games showcase, that technology can have
    unintended, negative consequences, why should we look at technology in
    an all positive light, seems to me the weak point of Messerly’s
    argument. It seems to me, that Messerly distinguishes between <em>types
    of technology</em>. Maybe Messerly assumes that there seems to be a
    category of technology where unintended consequences are more unlikely,
    or maybe even preferred, and another category, where those unintended
    consequences are making our lives worse. The issue is, as Messerly says,
    that we don’t know what the unintended consequences of technology are.
    Therefore we would have to look at only the intended consequences. Here,
    we could argue, that video games clearly are examples of bad, unwanted
    technology, because they served no productive purpose for humans. They
    “merely” entertain players and remove them from the “real world”.
    Whereas a chip that is implanted in the brain, to improve its cognitive
    functioning, is “good” technology, because it enhances humans in a
    productive way. The deciding factor would be the quality
    “productiveness” in the technology in question. But who is to say, what
    that quality is to be and who gets to decide it? That the chip can go
    bad and cause damage to the brain, or turn into a thought-controlling
    chip<a href="#fn1" class="footnote-ref" id="fnref1"
    role="doc-noteref"><sup>1</sup></a>, must be irrelevant on that account,
    because we cannot foresee this (although we can clearly imagine this
    outcome). Analogous, the same is true for video games. When we design
    video games, we cannot foresee that some players will become addicted to
    them. Therefore, we cannot prevent the development of video games on
    that premise, but rather because the core idea of video games, the
    intended consequences, seem to be contrary to what we want. But who is
    to decide, which intended consequences we want to accept? Even today,
    where technology is not as enhanced as in Joy’s thought experiment,
    there is next to no (public) discussion on the intended consequences of
    technology. The question: “Do we want to invite this technology into our
    lives, together with the intended changes it has on our lives?”, is
    seldom, if ever, discussed. We would need an instance, a group of people
    that decides what technology to allow and what technology to forbid. We
    can imagine a scenario where video games, with their non-productive use,
    would be forbidden, while brain implants would be allowed. But this
    approach would be dangerous and reckless. Dangerous, because who is to
    say that the decision that these experts make, are in the interest of
    the people? And reckless, because ignoring unintended consequences is
    like a head-first jump into potential shallow water. It is not wise to
    do. It’s like planning an undertaking and ignoring all potential causes
    of failure. Sure, they may be unlikely, but should we not talk about
    them? And if we see that the chances of success are more unlikely than
    the chances of failure, are we wiser in taking the risk, or in taking a
    step back and rethinking our choices?</p>
    <p>The second question, concerning the term “real world”, is a tricky
    one. Messerly argues, that Joy’s fear of nanotechnology and the human
    enhancement project in general, that is, for example, the uploading of
    the human mind into a computer, or the merge of humans and computers, is
    unfounded, because human beings are always evolving and in case of
    standstill, where we stopped our development, many people would prefer
    death to such a standstill<a href="#fn2" class="footnote-ref"
    id="fnref2" role="doc-noteref"><sup>2</sup></a>. But if we intervened
    with “normal” evolution and changed our nature with technological means,
    wouldn’t this be an intervention with the “real world”? What, then, is
    the “real world”, after all? Is it that thing that we were born within,
    the untouched world? Or is not rather that the “real world” is
    constantly effected by us, therefore turning into a fluid concept? If
    video games, that is, a type of technology, seems to take people away
    from the real world, with all its hardships, joy etc., to a place where
    these experiences don’t exist, why is it, that Messerly seems to openly
    invite a future, where we change ourselves (and therefore, the “real
    world”) in a way that we lack certain experience, either because we use
    technology to disable certain emotions (like suffering and pain), or
    because we become part of a giant supercomputer that, for example,
    removes all hardship from our lives? How can Messerly argue that it is
    bad that video games remove one from the “real world”, while arguing
    that in other cases it is not a bad thing at all? On what basis can we
    decide, with which technology these removals from the “real world” are
    good, and which are bad ones? And in how far are we willing to stretch
    our definition of the “real world”, to accommodate our technological
    changes? Video games are, in a way, the ultimate experience of a virtual
    reality. Any thinkable limitations that are put on us in the “real
    world” can be lifted by games. In a way, game designers are the gods of
    their creation. Interestingly, it seems to me that Messerly contradicts
    himself, when he on the one hand chides video games, because their
    virtual reality removes players from the “real world”, while on the
    other hand argues that for the human enhancement project he knows of “no
    reason (…) to impede our increasing abilities to perfect our bodies,
    eliminate disease, and prevent deformity”. The human enhancement
    project, taken to its most extreme form, is similar to the ultimate
    video games. Humans are being upgraded in a way that presents them with
    next to no limitations. But we have to ask: Would this still be the
    “real world”? Would we not loose the meaning of the concept “real
    world”? And if Messerly argues that in this case it would be a good
    thing, it seems only reasonably to ask about the differences between
    “living” in a video game and living as enhanced human being? What would
    be the difference if we remove all the hardship from life and existed
    just like in a video game? If we were able to remove any unwanted
    emotions? If we reverse aging or trick death to live for a long time? If
    this were the case, how can we draw the line between technologies that
    change us for better and those that change us for better? How, if not by
    limiting at least the development of certain technologies, <em>until we
    have a better understanding of them</em>? My point is not to go the
    pessimistic route and stay at the same place, technology-wise. Rather I
    propose a view, where we change our view on technology and development
    as such. Instead of plunging head first into new technology, we should
    assert the changes it makes on humans as such. Maybe we should change
    our view on technology to be similar to medicine. Just as medicine helps
    the body fight of disease, so technology helps humans in various aspects
    of their lives. While there seems (or should be) no controversy over the
    fact, that the uncontrolled use of new, insufficient studied, medicine
    is reckless, we should also come to conclude that the uncontrolled use
    and distribution of unstudied technology is just as reckless.</p>
    <p>Although I spent much of this essay discussing Messerly’s optimistic
    point of view, I now want to take a step back and briefly discuss both
    viewpoints from a neutral point of view. It is true that the
    uncontrolled development of technology might lead to disastrous
    outcomes. We can - and should - imagine scenarios where technology turns
    rogue and takes control over our lives. We should imagine it, so that we
    can implement safety measure and introduce responsible interactions with
    technology. But we shouldn’t refrain from developing and studying
    technology altogether. Of course that implies that we should neither be
    too optimistic nor too pessimistic. We should seek for the middle ground
    and understand ourselves as a species that creates itself through
    technology, and not the other way around. We should start a discussion
    about the changes we would like to make and about the limits we want to
    impose on us. This is one part of the ethical discussion of
    technology.</p>
    <p>One point that we should always keep in mind, is the goal of
    technological advance. Why do we develop and study new technology? Is it
    an end in itself, or do we strive for a higher goal? One possible, and
    undeniably important, goal of technological advance seems to me the
    continuing survival of humanity. Given the fragile state we are in,
    considering dangers on our planet (for example: climate change and
    depletion of resources), and dangers from out of space (for example:
    asteroids, comets and solar flares), we should seek to find ways to
    extend survival for as long as possible. Technology is our only and best
    bet. Of course there are dangers on the road ahead. A society that
    solely relies on technology can find itself in great peril, should the
    technology stop working. If all our knowledge is concentrated in
    technology and more and more of our lives are automated and taken over
    by AI, one blackout is enough to cripple all of life and endanger the
    survival of humanity. While there are great advantages in advancing
    technology, we shouldn’t forget the old ways, that in case of
    catastrophes enable us to continue our lives, even if with less comfort
    than today.</p>
    <p>In this essay I looked at two different viewpoints on technological
    advancement. I discussed Bill Joy’s pessimistic view that concludes that
    we should limit or even prevent the development and study of technology
    that poses a threat to humanities continued survival. Then I discussed
    John G. Messerly’s optimistic view that argues that, because cannot know
    what will happen in future, we might as well assume that the best
    possible outcome is to be expected and that we there don’t need to limit
    or control the development and study of technology. I then went on to
    look more closely on Messerly’s optimistic view and contrasted it with
    his view on video games. I argued that, because video games are
    technology and Messerly sees severe problems with the unintended
    consequences of video games, it is not enough to look at the intended
    consequences only, instead we should think about possible unintended
    consequences and think of ways to disarm them. I argued that we should
    be more critical on which technology to invite into our lives and that
    we should think about the ways we would have to change to include some
    new technology into our lives.</p>
    <h1 class="unnumbered" id="references">References</h1>
    <div id="refs" class="references csl-bib-body hanging-indent"
    role="doc-bibliography">
    <div id="ref-whythefuture" class="csl-entry" role="doc-biblioentry">
    Joy, Bill. 2000. <span>“Why the Future Doesn’t Need Us.”</span> <a
    href="https://www.wired.com/2000/04/joy-2/"
    class="uri">https://www.wired.com/2000/04/joy-2/</a>.
    </div>
    <div id="ref-imglad" class="csl-entry" role="doc-biblioentry">
    Messerly, John G. 2003. <span>“I’m Glad the Future Doesn’t Need Us: A
    Critique of Joy’s Pessimistic Futurism.”</span> <em>ACM SIGCAS Computers
    and Society</em> 33 (2).
    </div>
    <div id="ref-howcomputergames" class="csl-entry" role="doc-biblioentry">
    ———. 2004. <span>“How Computer Games Affect CS (and Other) Students’
    School Performance.”</span> <em>Communications of the ACM</em> 47 (3).
    </div>
    </div>
    <section class="footnotes footnotes-end-of-document"
    role="doc-endnotes">
    <hr />
    <ol>
    <li id="fn1" role="doc-endnote"><p>Of course we must not ignore that
    sometimes the intended consequences of technology include the harm,
    physically or psychically, of humans, animals or the environment. Some
    modern video games are designed in a way that enhances their addictive
    potential to draw players in to spend more money. In that case we can
    decide, based on intended consequences, that we want to regulate the
    technology in question.<a href="#fnref1" class="footnote-back"
    role="doc-backlink">↩︎</a></p></li>
    <li id="fn2" role="doc-endnote"><p>I don’t agree with Messerly on this
    point, because the idea that technological progress is part of what it
    means to be human is a relatively recent idea. There was no such concept
    in earlier times, which leads me to assume that we would (re-)grow
    accustomed to it. Still, arguing for or against this is not the point of
    the essay, which is why I leave it aside.<a href="#fnref2"
    class="footnote-back" role="doc-backlink">↩︎</a></p></li>
    </ol>
    </section>
    